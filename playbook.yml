# TODO: Finnish Ubuntu support
---
- hosts: all
  any_errors_fatal: true
  vars:
        create: false                                           # set to true if creating a new logical volume (do not set extend or resize to true)
        config_lvm: false                                       # must be set to true in order to execute any tasks in play (failsafe option :)- )
        kafka_user: kafka
        kafka_group: kafka
        jdk_version: 8
        new_disk: '/dev/sdb'                               # set to new disk being added to volume group
        new_mntp: '/kafkafs'                               # set to the desired mount point to be created and new logical volume to be mounted to
        create_lvname: 'kafka_lv'                          # set to logical volume name to create
        create_vgname: 'kafka_vg'                          # set to volume group name to create
        create_lvsize: '10G'                               # set to logical volume size to create --- (10G) - would create new lvm with 10Gigabytes -- (512) - would create new lvm with 512m
        filesystem: 'ext4'                                 # set to filesystem type to format new logical volume with ( ext3, ext4, xfs, etc. )
        confluent_version: '2.0.1'                         # valid values are 2.0.1 and 3.1.1 for now
        confluent_enterprise: false
        # Platforms version
        cp_version: '4.0'
        # Scala instalation version
        scala_version: '2.11'
        # Kafka configuration directory
        #kafka_conf_dir: /etc/kafka
        # Zookeeper data directory
        #zookeeper_data_dir: /var/lib/zookeeper
        # Kafka data directory
        #kafka_data_dir: /var/lib/kafka
        # Schema Registry configuration directory
        #schema_conf_dir: /etc/schema-registry
        # Kafka Utils directory
        #kafka_utils_dir: "/etc/kafka_discovery"

  tasks:
    - name: creating new LVM volume group
      lvg: vg={{ create_vgname }} pvs={{ new_disk }} state=present
      when: create and config_lvm

    - name: creating new LVM logical volume
      lvol: vg={{ create_vgname }} lv={{ create_lvname }} size={{ create_lvsize }}
      when: create and config_lvm

    - name: creating new filesystem on new LVM logical volume
      filesystem: fstype={{ filesystem }} dev=/dev/{{ create_vgname }}/{{ create_lvname }}
      when: create and config_lvm

    - name: mounting new filesystem
      mount: name={{ new_mntp }} src=/dev/{{ create_vgname }}/{{ create_lvname }} fstype={{ filesystem }} state=mounted
      when: create and config_lvm

    - name: Create kafka group
      group: 
        name: "{{ kafka_group}}"
        state: present
      become: true

    - name: Create kafka user
      user: name={{ kafka_user}} comment="Kafka application user" group={{kafka_group}}
      become: true

    - name: Change owner of {{new_mntp}} to {{kafka_user}}:{{kafka_group}} recursively
      file: path={{new_mntp}} recurse=true owner={{kafka_user}} group={{kafka_group}}
      become: true

    - name: Install JDK {{jdk_version}}
      apt:
          name: default-jre
          state: present
      become: true

    - name: Installing additional packages
      apt:
          name: "{{ item }}"
          state: present
      with_items:
        - build-essential
        - libssl-dev
        - libffi-dev
        - python-dev
        - python-crypto
      become: true

    - name: Install python-selinux
      apt:
          name: python-selinux
          state: present
      become: true

    - name: Adding an APT signing key, will not download if present
      apt_key:
        validate_certs: no
        url: "http://packages.confluent.io/deb/{{ cp_version }}/archive.key"
        state: present
      become: true

    - name: Adding repository to apt sources
      apt_repository:
          repo: "deb [arch=amd64] https://packages.confluent.io/deb/{{ cp_version }} stable main"
          state: present
      become: true

    # Ubuntu playbook install
    - name: Update repositories cache and install confluent-platform package
      apt:
          name: "confluent-platform-oss-{{ scala_version }}"
          state: present
          update_cache: yes
      become: true
    
    - name: Installing Confluent Platform
      apt:
          name: confluent-kafka-{{ scala_version }}
          state: present
      when: (confluent_version == "2.0.1")
      become: true

    - name: Installing Confluent Open Source
      apt:
          name:  confluent-platform-oss-{{ scala_version }}
          state: present
      when: (confluent_version ==  "3.1.1") and (not confluent_enterprise)
      become: true

    - name: Installing  Confluent Enterprise
      apt:
          name:  confluent-platform-{{ scala_version }}
          state: present
      when: (confluent_version ==  "3.1.1") and confluent_enterprise
      become: true

    - name: Change owner of /var/log/kafka to {{kafka_user}}:{{kafka_group}}
      file: path="/var/log/kafka" recurse=true owner={{kafka_user}} group={{kafka_group}}

    - name: Configure /etc/kafka/zookeeper.properties
      template:
          src=zookeeper.j2
          dest=/etc/kafka/zookeeper.properties

    - name: Create zookeeper directory.
      file: dest={{new_mntp}}/zookeeper owner={{kafka_user}} group={{kafka_group}} state=directory

    - name: Create zookeeper directory.
      file: dest={{new_mntp}}/kafka owner={{kafka_user}} group={{kafka_group}} state=directory

    - name: Create myid files
      lineinfile: dest={{new_mntp}}/zookeeper/myid owner={{kafka_user}} group={{kafka_group}} line={{ broker_id + 1 }} create=yes

    - name: Configure kafka log.dirs
      ini_file:
          dest: /etc/kafka/server.properties
          section: null
          option: log.dirs
          value: "{{new_mntp}}/kafka"
          backup: yes

    - name: Configure kafka log.dirs
      ini_file:
          dest: /etc/kafka/server.properties
          section: null
          option: delete.topic.enable
          value: true
          backup: yes

    - debug: msg="Broker ID is set to be {{ broker_id }}"

    - name: Configure kafka broker.id
      ini_file:
          dest: /etc/kafka/server.properties
          section: null
          option: broker.id
          value: "{{ broker_id }}"
          backup: yes

    - name: Configure kafka zookeeper.connect
      ini_file:
          dest: /etc/kafka/server.properties
          section: null
          option: zookeeper.connect
          value: "{% for node in play_hosts %}{{ hostvars[node]['ansible_host']  }}:2181{% if not loop.last %},{% endif %}{% endfor %}"
          backup: yes

    - name: Configure kafka advertised.host.name
      ini_file:
          dest: /etc/kafka/server.properties
          section: null
          option: advertised.host.name
          value: "{{ ansible_host }}"
          backup: yes

